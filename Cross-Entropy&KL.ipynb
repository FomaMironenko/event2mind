{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-etropy and Kullback-Leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    sys.path.insert(0, \"/usr/lib/python3.7/site-packages\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "import torch as t\n",
    "import pandas as pd\n",
    "import math\n",
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(tens: t.Tensor):\n",
    "    tmp = []\n",
    "    denom = float(t.sum(t.exp(tens)))\n",
    "    for i in range(tens.size()[0]):\n",
    "        tmp += [math.exp(tens[i])/denom]\n",
    "    return t.Tensor(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0723, 0.1966, 0.5344, 0.1966])\n"
     ]
    }
   ],
   "source": [
    "print(softmax(t.Tensor([1, 2, 3, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_softmax(gold_prob: t.Tensor, mod_prob: t.Tensor):\n",
    "    gold_prob = softmax(gold_prob.float())\n",
    "    mod_prob  = softmax(mod_prob.float())\n",
    "    # sum(p*log(q))\n",
    "    return float(-t.sum(t.mul( gold_prob, t.log2(mod_prob) )))\n",
    "\n",
    "def KL_divergention_softmax(gold_prob: t.Tensor, mod_prob: t.Tensor):\n",
    "    gold_prob = softmax(gold_prob.float())\n",
    "    mod_prob  = softmax(mod_prob.float())\n",
    "    # sum(p*log(q/p))\n",
    "    return float(-t.sum(t.mul( gold_prob, t.log2(t.div(mod_prob, gold_prob)) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.642784118652344"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = t.tensor([10, 1, 9])\n",
    "x2 = t.tensor([88.7, 2, 5])\n",
    "KL_divergention_softmax(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(x):\n",
    "    return [y.strip() for y in x[2:-2].replace('\"','').replace(\"'\",'').split(',')]\n",
    "def list2set(x):\n",
    "    return set(x)\n",
    "\n",
    "def uniq_events (test_df):\n",
    "    test_df[\"Xintent\"] = test_df[\"Xintent\"].apply(str2list)\n",
    "    test_df[\"Xemotion\"] = test_df[\"Xemotion\"].apply(str2list)\n",
    "    test_df[\"Otheremotion\"] = test_df[\"Otheremotion\"].apply(str2list)\n",
    "    test_df = test_df.groupby([\"Event\"])[\"Xintent\", \"Xemotion\", \"Otheremotion\"].sum()\n",
    "    \n",
    "    test_df[\"Xintent\"] = test_df[\"Xintent\"].apply(list2set)\n",
    "    test_df[\"Xemotion\"] = test_df[\"Xemotion\"].apply(list2set)\n",
    "    test_df[\"Otheremotion\"] = test_df[\"Otheremotion\"].apply(list2set)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## returns KL and soft_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_with_softmax(predictor, path_to_csv = 'event2mind/test.csv'):\n",
    "    gold_ds = pd.read_csv(path_to_csv)[['Event','Xintent','Xemotion','Otheremotion']]\n",
    "    gold_ds = uniq_events(gold_ds)\n",
    "    connected = {\"Xintent\": \"xintent\", \"Xemotion\": \"xreact\", \"Otheremotion\": \"oreact\"}\n",
    "    average = 0\n",
    "    L = gold_ds.shape[0]\n",
    "    counter = 0; n = 0\n",
    "    \n",
    "    gold_res = []\n",
    "    mod_res = []\n",
    "    for index, row in gold_ds.iterrows():\n",
    "        if(n == (counter*100)//L):\n",
    "            print(\"\\rCalculating: \" + str(n) + \"%\", end = \"\")\n",
    "            n += 1\n",
    "        for column_name in connected.keys():\n",
    "            result = predictor.predict(source=index)\n",
    "            model_out = [ (\" \".join(react), prob) for react, prob in zip(result[connected[column_name] + \"_top_k_predicted_tokens\"], result[connected[column_name] + \"_top_k_log_probabilities\"])]\n",
    "            gold_res += [len(row[column_name])]\n",
    "            mod_res  += [len(set(model_out[:10]) & row[column_name])]    \n",
    "        counter  += 1\n",
    "    print(\"\\r\", end = \"\")\n",
    "    return [KL_divergention_softmax(t.Tensor(gold_res), t.Tensor(mod_res)), cross_entropy_softmax(t.Tensor(gold_res), t.Tensor(mod_res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy:               12.7264\n",
      "Kullback-Leibler divergence: 1.8818\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/event2mind-2018.10.26.tar.gz\")\n",
    "KL_div, cross_entr = metrics_with_softmax(predictor)\n",
    "print(\"Cross-Entropy:              \", str(float('{:.4f}'.format(cross_entr))))\n",
    "print(\"Kullback-Leibler divergence:\", str(float('{:.4f}'.format(KL_div))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
