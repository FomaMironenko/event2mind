{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    sys.path.insert(0, \"/usr/lib/python3.7/site-packages\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "import torch as t\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(tens: t.Tensor):\n",
    "    tmp = []\n",
    "    denom = float(t.sum(t.exp(tens)))\n",
    "    for i in range(tens.size()[0]):\n",
    "        tmp += [math.exp(tens[i])/denom]\n",
    "    return t.Tensor(tmp)\n",
    "\n",
    "def cross_entropy_softmax(gold_prob: t.Tensor, mod_prob: t.Tensor):\n",
    "    gold_prob = softmax(gold_prob.float())\n",
    "    mod_prob  = softmax(mod_prob.float())\n",
    "    # sum(p*log(q))\n",
    "    return float(-t.sum(t.mul( gold_prob, t.log2(mod_prob) )))\n",
    "\n",
    "def KL_divergence_softmax(gold_prob: t.Tensor, mod_prob: t.Tensor):\n",
    "    gold_prob = softmax(gold_prob.float())\n",
    "    mod_prob  = softmax(mod_prob.float())\n",
    "    # sum(p*log(q/p))\n",
    "    return float(-t.sum(t.mul( gold_prob, t.log2(t.div(mod_prob, gold_prob)) )))\n",
    "\n",
    "def cross_entropy(gold_prob: t.Tensor, mod_prob: t.Tensor):\n",
    "    denom1 = float(t.sum(gold_prob))\n",
    "    denom2 = float(t.sum(mod_prob))\n",
    "    gold_prob = t.div(gold_prob.float(), denom1)\n",
    "    mod_prob  = t.div(mod_prob.float(), denom2)\n",
    "    return float(-t.sum(t.mul(gold_prob, t.log2(mod_prob))))\n",
    "\n",
    "def KL_divergence(gold_prob: t.Tensor, mod_prob: t.Tensor):\n",
    "    denom1 = float(t.sum(gold_prob))\n",
    "    denom2 = float(t.sum(mod_prob))\n",
    "    gold_prob = t.div(gold_prob.float(), denom1)\n",
    "    mod_prob  = t.div(mod_prob.float(), denom2)\n",
    "    return float(-t.sum(t.mul(gold_prob, t.log2(t.div(mod_prob, gold_prob)))))\n",
    "        \n",
    "def str2list(x):\n",
    "    return [y.strip() for y in x[2:-2].replace('\"','').replace(\"'\",'').replace(\".\", '').split(',')]\n",
    "def list2set(x):\n",
    "    return set(x)\n",
    "\n",
    "def uniq_events (test_df, dictionary):\n",
    "    test_df[\"Xintent\"] = test_df[\"Xintent\"].apply(str2list)\n",
    "    test_df[\"Xemotion\"] = test_df[\"Xemotion\"].apply(str2list)\n",
    "    test_df[\"Otheremotion\"] = test_df[\"Otheremotion\"].apply(str2list)\n",
    "    if(dictionary is not None):\n",
    "        dictionary = []\n",
    "        dictionary += (test_df[\"Xintent\"].sum() + test_df[\"Xemotion\"].sum() + test_df[\"Otheremotion\"].sum())\n",
    "        dictionary = set(dictionary)\n",
    "        dictionary = list(dictionary)\n",
    "    test_df = test_df.groupby([\"Event\"])[\"Xintent\", \"Xemotion\", \"Otheremotion\"].sum()\n",
    "    \n",
    "    test_df[\"Xintent\"] = test_df[\"Xintent\"].apply(list2set)\n",
    "    test_df[\"Xemotion\"] = test_df[\"Xemotion\"].apply(list2set)\n",
    "    test_df[\"Otheremotion\"] = test_df[\"Otheremotion\"].apply(list2set)\n",
    "    if(dictionary is not None):\n",
    "        return test_df, dictionary\n",
    "    else:\n",
    "        return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_output(dictionary):\n",
    "    n = random.randrange(1,10)\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        out += [dictionary[random.randrange(0,len(dictionary))]]\n",
    "    out += [\"none\"]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics using softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_with_softmax(predictor, rand_gen, path_to_csv = 'event2mind/test.csv'):\n",
    "    gold_ds = pd.read_csv(path_to_csv)[['Event','Xintent','Xemotion','Otheremotion']]\n",
    "    dictionary = []\n",
    "    if(not rand_gen):\n",
    "        dictionary = None\n",
    "        gold_ds = uniq_events(gold_ds, dictionary)\n",
    "    else:\n",
    "        gold_ds, dictionary = uniq_events(gold_ds, dictionary)\n",
    "    connected = {\"Xintent\": \"xintent\", \"Xemotion\": \"xreact\", \"Otheremotion\": \"oreact\"}\n",
    "    average = 0\n",
    "    L = gold_ds.shape[0]\n",
    "    counter = 0; n = 0\n",
    "    \n",
    "    gold_res = []\n",
    "    mod_res = []\n",
    "    for index, row in gold_ds.iterrows():\n",
    "        if(n == (counter*100)//L):\n",
    "            print(\"\\r\" + str(n) + \"%\" + \" \" + \"#\"*(n//2) + \"_\"*(50 - n//2), end = \"\")\n",
    "            n += 1\n",
    "        for column_name in connected.keys():\n",
    "            result = predictor.predict(source=index)\n",
    "            model_out = [ (\" \".join(react), prob) for react, prob in zip(result[connected[column_name] + \"_top_k_predicted_tokens\"], result[connected[column_name] + \"_top_k_log_probabilities\"])]\n",
    "            if(rand_gen):\n",
    "                tmp = rand_output(dictionary)\n",
    "                gold_res += [len(row[column_name])]\n",
    "                mod_res  += [len(set(tmp) & row[column_name])]\n",
    "            else:\n",
    "                gold_res += [len(row[column_name])]\n",
    "                mod_res  += [len(set([word[0] for word in model_out[:10]]) & row[column_name])]\n",
    "        counter  += 1\n",
    "    print(\"\\r\", end = \"\")\n",
    "    return [KL_divergence_softmax(t.Tensor(gold_res), t.Tensor(mod_res)), cross_entropy_softmax(t.Tensor(gold_res), t.Tensor(mod_res))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics without softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(predictor, rand_gen, path_to_csv = 'event2mind/test.csv'):\n",
    "    gold_ds = pd.read_csv(path_to_csv)[['Event','Xintent','Xemotion','Otheremotion']]\n",
    "    dictionary = []\n",
    "    if(not rand_gen):\n",
    "        dictionary = None\n",
    "        gold_ds = uniq_events(gold_ds, dictionary)\n",
    "    else:\n",
    "        gold_ds, dictionary = uniq_events(gold_ds, dictionary)\n",
    "    connected = {\"Xintent\": \"xintent\", \"Xemotion\": \"xreact\", \"Otheremotion\": \"oreact\"}\n",
    "    average = 0\n",
    "    L = gold_ds.shape[0]\n",
    "    counter = 0; n = 0\n",
    "    \n",
    "    gold_res = []\n",
    "    mod_res = []\n",
    "    for index, row in gold_ds.iterrows():\n",
    "        if(n == (counter*100)//L):\n",
    "            print(\"\\r\" + str(n) + \"%\" + \" \" + \"#\"*(n//2) + \"_\"*(50 - n//2), end = \"\")\n",
    "            n += 1\n",
    "        for column_name in connected.keys():\n",
    "            result = predictor.predict(source=index)\n",
    "            model_out = [ (\" \".join(react), prob) for react, prob in zip(result[connected[column_name] + \"_top_k_predicted_tokens\"], result[connected[column_name] + \"_top_k_log_probabilities\"])]\n",
    "            if(rand_gen):\n",
    "                tmp = rand_output(dictionary)\n",
    "                gold_res += [len(row[column_name])]\n",
    "                mod_res  += [len(set(tmp) & (row[column_name] | set([\"none\"])))]\n",
    "            else:\n",
    "                gold_res += [len(row[column_name])]\n",
    "                mod_res  += [len(set([word[0] for word in model_out[:10]] + [\"none\"]) & (row[column_name] | set([\"none\"])))]\n",
    "        counter  += 1\n",
    "    print(\"\\r\", end = \"\")\n",
    "    return [KL_divergence(t.Tensor(gold_res), t.Tensor(mod_res)), cross_entropy(t.Tensor(gold_res), t.Tensor(mod_res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  Cross-Entropy:  12.7337                          \n",
      "Model Kullback-Leibler divergence: 0.2267                           \n",
      "\n",
      "Random Cross-Entropy:  12.7266                          \n",
      "Random Kullback-Leibler divergence: 0.2196                           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/event2mind-2018.10.26.tar.gz\")\n",
    "\n",
    "KL_div, cross_entr = metrics(predictor, rand_gen=False)\n",
    "print(\"Model  Cross-Entropy: \", str(float('{:.4f}'.format(cross_entr))), ' '*25)\n",
    "print(\"Model Kullback-Leibler divergence:\", str(float('{:.4f}'.format(KL_div))), ' '*25, \"\\n\")\n",
    "\n",
    "KL_div, cross_entr = metrics(predictor, rand_gen=True)\n",
    "print(\"Random Cross-Entropy: \", str(float('{:.4f}'.format(cross_entr))), ' '*25)\n",
    "print(\"Random Kullback-Leibler divergence:\", str(float('{:.4f}'.format(KL_div))), ' '*25, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  Cross-Entropy:               12.8566                     \n",
      "Model  Kullback-Leibler divergence: 1.9641                     \n",
      "Random Cross-Entropy:               13.224                     \n",
      "Random Kullback-Leibler divergence: 2.3315                     \n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/event2mind-2018.10.26.tar.gz\")\n",
    "KL_div, cross_entr = metrics_with_softmax(predictor, rand_gen=False)\n",
    "print(\"Softmaxed:\\n\")\n",
    "print(\"Model  Cross-Entropy:              \", str(float('{:.4f}'.format(cross_entr))), ' '*25)\n",
    "print(\"Model  Kullback-Leibler divergence:\", str(float('{:.4f}'.format(KL_div))), ' '*25, \"\\n\")\n",
    "\n",
    "KL_div, cross_entr = metrics_with_softmax(predictor, rand_gen=True)\n",
    "print(\"Random Cross-Entropy:              \", str(float('{:.4f}'.format(cross_entr))), ' '*25)\n",
    "print(\"Random Kullback-Leibler divergence:\", str(float('{:.4f}'.format(KL_div))), ' '*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
