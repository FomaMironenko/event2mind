{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_small = Predictor.from_path(\"ser_dir_original_model/model.tar.gz\")\n",
    "predictor_large = Predictor.from_path(\"ser_dir_large_model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем данные из test.csv, парсим по колонкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')[['Event','Xintent','Xemotion','Otheremotion']]\n",
    "def str2list(x):\n",
    "    return [y.strip() for y in x[2:-2].replace('\"','').replace(\"'\",'').split(',')]\n",
    "for col in ['Xintent','Xemotion','Otheremotion']:\n",
    "    test_df[col] = test_df[col].apply(str2list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Группируем по фразам отдельно намерения, эмоции субъекта и эмоции окружающих"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_word(w):\n",
    "    x = w\n",
    "    if x[:3] == 'is ' or x[:3] == 'to ':\n",
    "        x = x[3:]\n",
    "    if x[:3] == 'be ':\n",
    "        x = x[3:]\n",
    "    if x[len(x) - 1] == '.':\\\n",
    "        x = x[:len(x)-1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase2oemotion = {}\n",
    "phrase2xemotion = {}\n",
    "phrase2xintent = {}\n",
    "res_xi = []\n",
    "res_xe = []\n",
    "res_oe = []\n",
    "set_xi = set()\n",
    "set_xe = set()\n",
    "set_oe = set()\n",
    "\n",
    "phrase_set = set([x for x in test_df.Event])\n",
    "\n",
    "for phrase in phrase_set:\n",
    "    for x in test_df[test_df.Event == phrase].Xintent:\n",
    "        res_xi += x\n",
    "    phrase2xintent[phrase] = set()\n",
    "    for x in set(res_xi):\n",
    "        if x != '':\n",
    "            phrase2xintent[phrase].add(clear_word(x))\n",
    "    res_xi.clear()\n",
    "    \n",
    "    for x in test_df[test_df.Event == phrase].Xemotion:\n",
    "        res_xe += x\n",
    "    phrase2xemotion[phrase] = set()\n",
    "    for x in set(res_xe):\n",
    "        if x != '':\n",
    "            phrase2xemotion[phrase].add(clear_word(x))\n",
    "    res_xe.clear()\n",
    "    \n",
    "    for x in test_df[test_df.Event == phrase].Otheremotion:\n",
    "        res_oe += x\n",
    "    phrase2oemotion[phrase] = set()\n",
    "    for x in set(res_oe):\n",
    "        if x != '':\n",
    "            phrase2oemotion[phrase].add(clear_word(x))\n",
    "    res_oe.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"PersonX takes a nap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'help a headache go away',\n",
       " 'not be tired',\n",
       " 'rest',\n",
       " 'sleep',\n",
       " 'take a break',\n",
       " 'tired'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase2xintent[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'get rest',\n",
       " 'get some rest',\n",
       " 'get to work',\n",
       " 'have fun',\n",
       " 'relax',\n",
       " 'rest',\n",
       " 'rest .',\n",
       " 'rested',\n",
       " 'sleep',\n",
       " 'take rest'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predictor_large.predict(source=p)\n",
    "\n",
    "oreact = set([\" \".join(react) for react in result[\"oreact_top_k_predicted_tokens\"]])    \n",
    "intents = set([\" \".join(react) for react in result[\"xintent_top_k_predicted_tokens\"]])\n",
    "xreact = set([\" \".join(react) for react in result[\"xreact_top_k_predicted_tokens\"]])\n",
    "\n",
    "intents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем recall следующим образом: из всех вариантов, выданных моделью для данной фразы, оставляем те, что есть в контрольном множестве фразы, сформированном ранее, и делим их количество на размер контрольного множества. Затем делим полученную сумму на количество фраз. Проделываем для каждого из выходов (intent, xreact и oreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.2453708973629289\n",
      "Recall for x_react:  0.25397246990872446\n",
      "Recall for o_react:  0.6486898964986609\n"
     ]
    }
   ],
   "source": [
    "res_oe = 0\n",
    "res_xe = 0\n",
    "res_xi = 0\n",
    "\n",
    "for phrase in phrase_set:\n",
    "    result = predictor_small.predict(source=phrase)\n",
    "\n",
    "    oreact = set([\" \".join(react) for react in result[\"oreact_top_k_predicted_tokens\"]])    \n",
    "    intents = set([\" \".join(react) for react in result[\"xintent_top_k_predicted_tokens\"]])\n",
    "    xreact = set([\" \".join(react) for react in result[\"xreact_top_k_predicted_tokens\"]])\n",
    "\n",
    "    res_oe += len(phrase2oemotion[phrase].intersection(oreact)) / len(phrase2oemotion[phrase])\n",
    "    res_xe += len(phrase2xemotion[phrase].intersection(xreact)) / len(phrase2xemotion[phrase])\n",
    "    res_xi += len(phrase2xintent[phrase].intersection(intents)) / len(phrase2xintent[phrase])\n",
    "\n",
    "print(\"Recall for intents: \", res_xi / len(phrase_set))\n",
    "print(\"Recall for x_react: \", res_xe / len(phrase_set))\n",
    "print(\"Recall for o_react: \", res_oe / len(phrase_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.29091148632981323\n",
      "Recall for x_react:  0.17863993760408028\n",
      "Recall for o_react:  0.6410126689011149\n"
     ]
    }
   ],
   "source": [
    "res_oe = 0\n",
    "res_xe = 0\n",
    "res_xi = 0\n",
    "\n",
    "for phrase in phrase_set:\n",
    "    result = predictor_large.predict(source=phrase)\n",
    "\n",
    "    oreact = set([\" \".join(react) for react in result[\"oreact_top_k_predicted_tokens\"]])    \n",
    "    intents = set([\" \".join(react) for react in result[\"xintent_top_k_predicted_tokens\"]])\n",
    "    xreact = set([\" \".join(react) for react in result[\"xreact_top_k_predicted_tokens\"]])\n",
    "\n",
    "    res_oe += len(phrase2oemotion[phrase].intersection(oreact)) / len(phrase2oemotion[phrase])\n",
    "    res_xe += len(phrase2xemotion[phrase].intersection(xreact)) / len(phrase2xemotion[phrase])\n",
    "    res_xi += len(phrase2xintent[phrase].intersection(intents)) / len(phrase2xintent[phrase])\n",
    "\n",
    "print(\"Recall for intents: \", res_xi / len(phrase_set))\n",
    "print(\"Recall for x_react: \", res_xe / len(phrase_set))\n",
    "print(\"Recall for o_react: \", res_oe / len(phrase_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.2910334637589951\n",
      "Recall for x_react:  0.18088990432411264\n",
      "Recall for o_react:  0.634825931905035\n"
     ]
    }
   ],
   "source": [
    "res_oe = 0\n",
    "res_xe = 0\n",
    "res_xi = 0\n",
    "count = 0\n",
    "\n",
    "for phrase in phrase_set:\n",
    "    result = predictor_large.predict(source=phrase)\n",
    "\n",
    "    oreact = set([\" \".join(react) for react in result[\"oreact_top_k_predicted_tokens\"]])    \n",
    "    intents = set([\" \".join(react) for react in result[\"xintent_top_k_predicted_tokens\"]])\n",
    "    xreact = set([\" \".join(react) for react in result[\"xreact_top_k_predicted_tokens\"]])\n",
    "\n",
    "    res_oe += len(phrase2oemotion[phrase].intersection(oreact)) / len(phrase2oemotion[phrase]) * test_df[test_df.Event == phrase].shape[0]\n",
    "    res_xe += len(phrase2xemotion[phrase].intersection(xreact)) / len(phrase2xemotion[phrase]) * test_df[test_df.Event == phrase].shape[0]\n",
    "    res_xi += len(phrase2xintent[phrase].intersection(intents)) / len(phrase2xintent[phrase]) * test_df[test_df.Event == phrase].shape[0]\n",
    "    \n",
    "    count += test_df[test_df.Event == phrase].shape[0]\n",
    "\n",
    "print(\"Recall for intents: \", res_xi / count)\n",
    "print(\"Recall for x_react: \", res_xe / count)\n",
    "print(\"Recall for o_react: \", res_oe / count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
