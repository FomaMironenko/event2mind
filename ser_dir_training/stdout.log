2019-11-05 11:35:15,268 - INFO - allennlp.common.params - random_seed = 13370
2019-11-05 11:35:15,268 - INFO - allennlp.common.params - numpy_seed = 1337
2019-11-05 11:35:15,268 - INFO - allennlp.common.params - pytorch_seed = 133
2019-11-05 11:35:15,373 - INFO - allennlp.common.checks - Pytorch version: 1.2.0
2019-11-05 11:35:15,374 - INFO - allennlp.common.params - evaluate_on_test = False
2019-11-05 11:35:15,374 - INFO - allennlp.common.params - validation_dataset_reader = None
2019-11-05 11:35:15,374 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'dummy_instances_for_vocab_generation': True, 'source_token_indexers': {'tokens': {'namespace': 'source_tokens', 'type': 'single_id'}}, 'source_tokenizer': {'type': 'spacy'}, 'type': 'event2mind1'} and extras set()
2019-11-05 11:35:15,374 - INFO - allennlp.common.params - dataset_reader.type = event2mind1
2019-11-05 11:35:15,374 - INFO - allennlp.common.from_params - instantiating class <class 'event2mind1.Event2MindDatasetReader'> from params {'dummy_instances_for_vocab_generation': True, 'source_token_indexers': {'tokens': {'namespace': 'source_tokens', 'type': 'single_id'}}, 'source_tokenizer': {'type': 'spacy'}} and extras set()
2019-11-05 11:35:15,374 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'spacy'} and extras set()
2019-11-05 11:35:15,374 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.type = spacy
2019-11-05 11:35:15,374 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.spacy_tokenizer.SpacyTokenizer'> from params {} and extras set()
2019-11-05 11:35:15,375 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.language = en_core_web_sm
2019-11-05 11:35:15,375 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.pos_tags = False
2019-11-05 11:35:15,375 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.parse = False
2019-11-05 11:35:15,375 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.ner = False
2019-11-05 11:35:15,375 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.keep_spacy_tokens = False
2019-11-05 11:35:15,375 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.split_on_spaces = False
2019-11-05 11:35:15,375 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.start_tokens = None
2019-11-05 11:35:15,375 - INFO - allennlp.common.params - dataset_reader.source_tokenizer.end_tokens = None
2019-11-05 11:35:15,552 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'namespace': 'source_tokens', 'type': 'single_id'} and extras set()
2019-11-05 11:35:15,552 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.type = single_id
2019-11-05 11:35:15,552 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer'> from params {'namespace': 'source_tokens'} and extras set()
2019-11-05 11:35:15,552 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.namespace = source_tokens
2019-11-05 11:35:15,552 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.lowercase_tokens = False
2019-11-05 11:35:15,552 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.start_tokens = None
2019-11-05 11:35:15,552 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.end_tokens = None
2019-11-05 11:35:15,552 - INFO - allennlp.common.params - dataset_reader.source_token_indexers.tokens.token_min_padding_length = 0
2019-11-05 11:35:15,552 - INFO - allennlp.common.params - dataset_reader.target_token_indexers = <allennlp.common.params.Params object at 0x7fd3f7251470>
2019-11-05 11:35:15,552 - INFO - allennlp.common.params - dataset_reader.source_add_start_token = True
2019-11-05 11:35:15,553 - INFO - allennlp.common.params - dataset_reader.dummy_instances_for_vocab_generation = True
2019-11-05 11:35:15,553 - INFO - allennlp.common.params - dataset_reader.lazy = False
2019-11-05 11:35:15,553 - INFO - allennlp.common.params - train_data_path = https://raw.githubusercontent.com/uwnlp/event2mind/master/docs/data/train.csv
2019-11-05 11:35:15,553 - INFO - allennlp.training.util - Reading training data from https://raw.githubusercontent.com/uwnlp/event2mind/master/docs/data/train.csv
2019-11-05 11:35:16,346 - INFO - event2mind1 - Reading instances from lines in file at: https://raw.githubusercontent.com/uwnlp/event2mind/master/docs/data/train.csv
2019-11-05 11:39:05,882 - INFO - allennlp.common.params - validation_data_path = https://raw.githubusercontent.com/uwnlp/event2mind/master/docs/data/dev.csv
2019-11-05 11:39:05,882 - INFO - allennlp.training.util - Reading validation data from https://raw.githubusercontent.com/uwnlp/event2mind/master/docs/data/dev.csv
2019-11-05 11:39:06,532 - INFO - event2mind1 - Reading instances from lines in file at: https://raw.githubusercontent.com/uwnlp/event2mind/master/docs/data/dev.csv
2019-11-05 11:39:32,575 - INFO - allennlp.common.params - test_data_path = None
2019-11-05 11:39:32,723 - INFO - allennlp.training.trainer_pieces - From dataset instances, train, validation will be considered for vocabulary creation.
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.type = None
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.extend = False
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.directory_path = None
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.min_count = {'source_tokens': 2}
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False
2019-11-05 11:39:32,723 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2019-11-05 11:39:32,723 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2019-11-05 11:39:34,272 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'embedding_dropout': 0.2, 'encoder': {'bidirectional': True, 'hidden_size': 50, 'input_size': 300, 'num_layers': 1, 'type': 'gru'}, 'max_decoding_steps': 10, 'source_embedder': {'token_embedders': {'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://allennlp.s3.amazonaws.com/datasets/word2vec/GoogleNews-vectors-negative300.txt.gz', 'trainable': False, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}}, 'target_namespace': 'source_tokens', 'type': 'event2mind1'} and extras {'vocab'}
2019-11-05 11:39:34,272 - INFO - allennlp.common.params - model.type = event2mind1
2019-11-05 11:39:34,272 - INFO - allennlp.common.from_params - instantiating class <class 'event2mind1.Event2Mind'> from params {'embedding_dropout': 0.2, 'encoder': {'bidirectional': True, 'hidden_size': 50, 'input_size': 300, 'num_layers': 1, 'type': 'gru'}, 'max_decoding_steps': 10, 'source_embedder': {'token_embedders': {'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://allennlp.s3.amazonaws.com/datasets/word2vec/GoogleNews-vectors-negative300.txt.gz', 'trainable': False, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}}, 'target_namespace': 'source_tokens'} and extras {'vocab'}
2019-11-05 11:39:34,273 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'embedding_dim': 300, 'pretrained_file': 'https://allennlp.s3.amazonaws.com/datasets/word2vec/GoogleNews-vectors-negative300.txt.gz', 'trainable': False, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}} and extras {'vocab'}
2019-11-05 11:39:34,273 - INFO - allennlp.common.params - model.source_embedder.type = basic
2019-11-05 11:39:34,273 - INFO - allennlp.common.params - model.source_embedder.embedder_to_indexer_map = None
2019-11-05 11:39:34,273 - INFO - allennlp.common.params - model.source_embedder.allow_unmatched_keys = False
2019-11-05 11:39:34,273 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'pretrained_file': 'https://allennlp.s3.amazonaws.com/datasets/word2vec/GoogleNews-vectors-negative300.txt.gz', 'trainable': False, 'type': 'embedding', 'vocab_namespace': 'source_tokens'} and extras {'vocab'}
2019-11-05 11:39:34,273 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.type = embedding
2019-11-05 11:39:34,273 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.num_embeddings = None
2019-11-05 11:39:34,273 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.vocab_namespace = source_tokens
2019-11-05 11:39:34,273 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.embedding_dim = 300
2019-11-05 11:39:34,273 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.pretrained_file = https://allennlp.s3.amazonaws.com/datasets/word2vec/GoogleNews-vectors-negative300.txt.gz
2019-11-05 11:39:34,274 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.projection_dim = None
2019-11-05 11:39:34,274 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.trainable = False
2019-11-05 11:39:34,274 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.padding_index = None
2019-11-05 11:39:34,274 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.max_norm = None
2019-11-05 11:39:34,274 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.norm_type = 2.0
2019-11-05 11:39:34,274 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.scale_grad_by_freq = False
2019-11-05 11:39:34,274 - INFO - allennlp.common.params - model.source_embedder.token_embedders.tokens.sparse = False
2019-11-05 11:39:34,275 - INFO - allennlp.modules.token_embedders.embedding - Reading pretrained embeddings from file
2019-11-05 11:40:40,358 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer
2019-11-05 11:40:40,805 - INFO - allennlp.modules.token_embedders.embedding - Pretrained embeddings were found for 8170 out of 8369 tokens
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - model.embedding_dropout = 0.2
2019-11-05 11:40:40,809 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': True, 'hidden_size': 50, 'input_size': 300, 'num_layers': 1, 'type': 'gru'} and extras {'vocab'}
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - model.encoder.type = gru
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - model.encoder.batch_first = True
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - model.encoder.bidirectional = True
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - model.encoder.hidden_size = 50
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - model.encoder.input_size = 300
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - model.encoder.num_layers = 1
2019-11-05 11:40:40,809 - INFO - allennlp.common.params - model.encoder.batch_first = True
2019-11-05 11:40:40,811 - INFO - allennlp.common.params - model.max_decoding_steps = 10
2019-11-05 11:40:40,811 - INFO - allennlp.common.params - model.beam_size = 10
2019-11-05 11:40:40,811 - INFO - allennlp.common.params - model.target_names = None
2019-11-05 11:40:40,811 - INFO - allennlp.common.params - model.target_namespace = source_tokens
2019-11-05 11:40:40,811 - INFO - allennlp.common.params - model.target_embedding_dim = None
2019-11-05 11:40:40,870 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.
2019-11-05 11:40:40,870 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.
2019-11-05 11:40:40,870 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.
2019-11-05 11:40:40,885 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'padding_noise': 0, 'sorting_keys': [['source', 'num_tokens']], 'type': 'bucket'} and extras set()
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.type = bucket
2019-11-05 11:40:40,885 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 64, 'padding_noise': 0, 'sorting_keys': [['source', 'num_tokens']]} and extras set()
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.sorting_keys = [['source', 'num_tokens']]
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.padding_noise = 0
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.biggest_batch_first = False
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.batch_size = 64
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.instances_per_epoch = None
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.cache_instances = False
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.track_epoch = False
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False
2019-11-05 11:40:40,885 - INFO - allennlp.common.params - validation_iterator = None
2019-11-05 11:40:40,886 - INFO - allennlp.common.params - trainer.no_grad = ()
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _source_embedder.token_embedder_tokens.weight
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _encoder._module.weight_ih_l0
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _encoder._module.weight_hh_l0
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _encoder._module.bias_ih_l0
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _encoder._module.bias_hh_l0
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _encoder._module.weight_ih_l0_reverse
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _encoder._module.weight_hh_l0_reverse
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _encoder._module.bias_ih_l0_reverse
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _encoder._module.bias_hh_l0_reverse
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xintent.embedder.weight
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xintent.decoder_cell.weight_ih
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xintent.decoder_cell.weight_hh
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xintent.decoder_cell.bias_ih
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xintent.decoder_cell.bias_hh
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xintent.output_projection_layer.weight
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xintent.output_projection_layer.bias
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xreact.embedder.weight
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xreact.decoder_cell.weight_ih
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xreact.decoder_cell.weight_hh
2019-11-05 11:40:40,886 - INFO - allennlp.training.trainer_pieces - _states.xreact.decoder_cell.bias_ih
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.xreact.decoder_cell.bias_hh
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.xreact.output_projection_layer.weight
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.xreact.output_projection_layer.bias
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.oreact.embedder.weight
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.oreact.decoder_cell.weight_ih
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.oreact.decoder_cell.weight_hh
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.oreact.decoder_cell.bias_ih
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.oreact.decoder_cell.bias_hh
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.oreact.output_projection_layer.weight
2019-11-05 11:40:40,887 - INFO - allennlp.training.trainer_pieces - _states.oreact.output_projection_layer.bias
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.patience = 10
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.validation_metric = +xintent
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.shuffle = True
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.num_epochs = 2
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.cuda_device = -1
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.grad_norm = None
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.grad_clipping = None
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.optimizer.type = adam
2019-11-05 11:40:40,887 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2019-11-05 11:40:40,896 - INFO - allennlp.training.optimizers - Number of trainable parameters: 10535307
2019-11-05 11:40:40,896 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True
2019-11-05 11:40:40,897 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-11-05 11:40:40,897 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-11-05 11:40:40,897 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20
2019-11-05 11:40:40,897 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None
2019-11-05 11:40:40,897 - INFO - allennlp.common.params - trainer.model_save_interval = None
2019-11-05 11:40:40,898 - INFO - allennlp.common.params - trainer.summary_interval = 100
2019-11-05 11:40:40,898 - INFO - allennlp.common.params - trainer.histogram_interval = None
2019-11-05 11:40:40,898 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True
2019-11-05 11:40:40,898 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False
2019-11-05 11:40:40,898 - INFO - allennlp.common.params - trainer.log_batch_size_period = None
2019-11-05 11:40:40,990 - INFO - allennlp.training.trainer - Beginning training.
2019-11-05 11:40:40,990 - INFO - allennlp.training.trainer - Epoch 0/1
2019-11-05 11:40:40,990 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1097.108
2019-11-05 11:40:41,107 - INFO - allennlp.training.trainer - Training
2019-11-05 11:52:12,253 - INFO - allennlp.training.trainer - Validating
2019-11-05 11:54:48,959 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-11-05 11:54:48,959 - INFO - allennlp.training.tensorboard_writer - oreact        |       N/A  |     0.895
2019-11-05 11:54:48,959 - INFO - allennlp.training.tensorboard_writer - loss          |     1.177  |     1.020
2019-11-05 11:54:48,960 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1097.108  |       N/A
2019-11-05 11:54:48,960 - INFO - allennlp.training.tensorboard_writer - xreact        |       N/A  |     0.740
2019-11-05 11:54:48,960 - INFO - allennlp.training.tensorboard_writer - xintent       |       N/A  |     0.775
2019-11-05 11:54:49,285 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'ser_dir_training/best.th'.
2019-11-05 11:54:49,474 - INFO - allennlp.training.trainer - Epoch duration: 0:14:08.483516
2019-11-05 11:54:49,474 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:14:08
2019-11-05 11:54:49,474 - INFO - allennlp.training.trainer - Epoch 1/1
2019-11-05 11:54:49,784 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 2399.072
2019-11-05 11:54:51,215 - INFO - allennlp.training.trainer - Training
2019-11-05 12:07:45,993 - INFO - allennlp.training.trainer - Validating
2019-11-05 12:10:26,571 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-11-05 12:10:26,571 - INFO - allennlp.training.tensorboard_writer - oreact        |       N/A  |     0.896
2019-11-05 12:10:26,572 - INFO - allennlp.training.tensorboard_writer - loss          |     1.002  |     0.987
2019-11-05 12:10:26,572 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  2399.072  |       N/A
2019-11-05 12:10:26,573 - INFO - allennlp.training.tensorboard_writer - xreact        |       N/A  |     0.741
2019-11-05 12:10:26,573 - INFO - allennlp.training.tensorboard_writer - xintent       |       N/A  |     0.785
2019-11-05 12:10:27,304 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'ser_dir_training/best.th'.
2019-11-05 12:10:27,900 - INFO - allennlp.training.trainer - Epoch duration: 0:15:38.425783
2019-11-05 12:10:28,655 - INFO - allennlp.training.checkpointer - loading best weights
