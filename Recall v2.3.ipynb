{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.data.tokenizers.tokenizer:Converting old WordTokenizer params - <allennlp.common.params.Params object at 0x7f9ea8dad278> \n",
      "to new params <allennlp.common.params.Params object at 0x7f9ea8dad6a0>.\n"
     ]
    }
   ],
   "source": [
    "predictor_small = Predictor.from_path(\"ser_dir_original_model/model.tar.gz\")\n",
    "predictor_large = Predictor.from_path(\"ser_dir_large_model/model.tar.gz\")\n",
    "predictor_orig = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/event2mind-2018.10.26.tar.gz\")\n",
    "predictor_mid = Predictor.from_path(\"ser_dir_5e_model/model.tar.gz\")\n",
    "predictor_xe = Predictor.from_path(\"xe_5e_model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем данные из test.csv, парсим по колонкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')[['Event','Xintent','Xemotion','Otheremotion']]\n",
    "def str2list(x):\n",
    "    return [y.strip() for y in x[2:-2].replace('\"','').replace(\"'\",'').split(',')]\n",
    "for col in ['Xintent','Xemotion','Otheremotion']:\n",
    "    test_df[col] = test_df[col].apply(str2list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Группируем по фразам отдельно намерения, эмоции субъекта и эмоции окружающих\n",
    "\n",
    "UPD: Убираем из строк не несущие смысла to, to be, is и точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_word(w):\n",
    "    x = w\n",
    "    if x[:3] == 'is ' or x[:3] == 'to ':\n",
    "        x = x[3:]\n",
    "    if x[:3] == 'be ':\n",
    "        x = x[3:]\n",
    "    if x[len(x) - 1] == '.':\\\n",
    "        x = x[:len(x)-1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase2oemotion = {}\n",
    "phrase2xemotion = {}\n",
    "phrase2xintent = {}\n",
    "res_xi = []\n",
    "res_xe = []\n",
    "res_oe = []\n",
    "set_xi = set()\n",
    "set_xe = set()\n",
    "set_oe = set()\n",
    "\n",
    "phrase_set = set([x for x in test_df.Event])\n",
    "\n",
    "for phrase in phrase_set:\n",
    "    for x in test_df[test_df.Event == phrase].Xintent:\n",
    "        res_xi += x\n",
    "    phrase2xintent[phrase] = set()\n",
    "    for x in set(res_xi):\n",
    "        if x != '':\n",
    "            phrase2xintent[phrase].add(clear_word(x))\n",
    "    res_xi.clear()\n",
    "    \n",
    "    for x in test_df[test_df.Event == phrase].Xemotion:\n",
    "        res_xe += x\n",
    "    phrase2xemotion[phrase] = set()\n",
    "    for x in set(res_xe):\n",
    "        if x != '':\n",
    "            phrase2xemotion[phrase].add(clear_word(x))\n",
    "    res_xe.clear()\n",
    "    \n",
    "    for x in test_df[test_df.Event == phrase].Otheremotion:\n",
    "        res_oe += x\n",
    "    phrase2oemotion[phrase] = set()\n",
    "    for x in set(res_oe):\n",
    "        if x != '':\n",
    "            phrase2oemotion[phrase].add(clear_word(x))\n",
    "    res_oe.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем recall следующим образом: из всех вариантов, выданных моделью для данной фразы, оставляем те, что есть в контрольном множестве фразы, сформированном ранее, и делим их количество на размер контрольного множества. Затем делим полученную сумму на количество фраз. Проделываем для каждого из выходов (intent, xreact и oreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_recall(predictor):\n",
    "    res_oe = 0\n",
    "    res_xe = 0\n",
    "    res_xi = 0\n",
    "\n",
    "    for phrase in phrase_set:\n",
    "        result = predictor.predict(source=phrase)\n",
    "\n",
    "        oreact = set([\" \".join(react) for react in result[\"oreact_top_k_predicted_tokens\"]])    \n",
    "        intents = set([\" \".join(react) for react in result[\"xintent_top_k_predicted_tokens\"]])\n",
    "        xreact = set([\" \".join(react) for react in result[\"xreact_top_k_predicted_tokens\"]])\n",
    "\n",
    "        res_oe += len(phrase2oemotion[phrase].intersection(oreact)) / len(phrase2oemotion[phrase])\n",
    "        res_xe += len(phrase2xemotion[phrase].intersection(xreact)) / len(phrase2xemotion[phrase])\n",
    "        res_xi += len(phrase2xintent[phrase].intersection(intents)) / len(phrase2xintent[phrase])\n",
    "\n",
    "    print(\"Recall for intents: \", res_xi / len(phrase_set))\n",
    "    print(\"Recall for x_react: \", res_xe / len(phrase_set))\n",
    "    print(\"Recall for o_react: \", res_oe / len(phrase_set))\n",
    "    print()\n",
    "    \n",
    "def count_recall_all():    \n",
    "    print(\"Model with xintent metric:\")\n",
    "    print()\n",
    "    #print(\"Recall of model trained for 10 epochs\")\n",
    "    #count_recall(predictor_large)\n",
    "    print(\"Recall of model trained for 5 epochs\")\n",
    "    count_recall(predictor_mid)\n",
    "    #print(\"Recall of model trained for 2 epochs\")\n",
    "    #count_recall(predictor_small)\n",
    "    print(\"Model with xreact metric:\")\n",
    "    count_recall(predictor_xe)\n",
    "    print(\"Recall of original model\")\n",
    "    count_recall(predictor_orig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with xintent metric:\n",
      "\n",
      "Recall of model trained for 5 epochs\n",
      "Recall for intents:  0.2824079343999665\n",
      "Recall for x_react:  0.19815658002908912\n",
      "Recall for o_react:  0.6493012078669446\n",
      "\n",
      "Model with xreact metric:\n",
      "Recall for intents:  0.2616591833723306\n",
      "Recall for x_react:  0.24602226016568596\n",
      "Recall for o_react:  0.649385526676363\n",
      "\n",
      "Recall of original model\n",
      "Recall for intents:  0.28737115031935784\n",
      "Recall for x_react:  0.38374596850692516\n",
      "Recall for o_react:  0.6953909230801655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_recall_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
