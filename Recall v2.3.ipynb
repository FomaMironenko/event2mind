{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.data.tokenizers.tokenizer:Converting old WordTokenizer params - <allennlp.common.params.Params object at 0x7f1bb1962e80> \n",
      "to new params <allennlp.common.params.Params object at 0x7f1bb1962978>.\n",
      "WARNING:allennlp.data.tokenizers.tokenizer:Converting old WordTokenizer params - <allennlp.common.params.Params object at 0x7f1bb1a166d8> \n",
      "to new params <allennlp.common.params.Params object at 0x7f1bb1a16630>.\n"
     ]
    }
   ],
   "source": [
    "predictor_small = Predictor.from_path(\"ser_dir_original_model/model.tar.gz\")\n",
    "predictor_large = Predictor.from_path(\"ser_dir_large_model/model.tar.gz\")\n",
    "predictor_orig = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/event2mind-2018.10.26.tar.gz\")\n",
    "predictor_mid = Predictor.from_path(\"ser_dir_5e_model/model.tar.gz\")\n",
    "predictor_xe = Predictor.from_path(\"xe_5e_model/model.tar.gz\")\n",
    "predictor_oe = Predictor.from_path(\"oe_5e_model/model.tar.gz\")\n",
    "predictor_xel = Predictor.from_path(\"xe_10e_model/model.tar.gz\")\n",
    "predictor_oel = Predictor.from_path(\"oe_10e_model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.data.tokenizers.tokenizer:Converting old WordTokenizer params - <allennlp.common.params.Params object at 0x7f1bb5738b00> \n",
      "to new params <allennlp.common.params.Params object at 0x7f1bb57380f0>.\n",
      "WARNING:allennlp.data.tokenizers.tokenizer:Converting old WordTokenizer params - <allennlp.common.params.Params object at 0x7f1bb523ff28> \n",
      "to new params <allennlp.common.params.Params object at 0x7f1bb523f518>.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictor_new_xi_2e = Predictor.from_path(\"xi_2e_new_model/model.tar.gz\")\n",
    "predictor_new_xi_10e = Predictor.from_path(\"xi_10e_new_model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_birnn300_xi_2e = Predictor.from_path(\"xi_2e_birnn300_model/model.tar.gz\")\n",
    "predictor_birnn300_xi_10e = Predictor.from_path(\"xi_10e_birnn300_model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cnn_xi_2e = Predictor.from_path(\"xi_2e_cnn_model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_alyona = Predictor.from_path(\"Alyona_model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем данные из test.csv, парсим по колонкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')[['Event','Xintent','Xemotion','Otheremotion']]\n",
    "def str2list(x):\n",
    "    return [y.strip() for y in x[2:-2].replace('\"','').replace(\"'\",'').split(',')]\n",
    "for col in ['Xintent','Xemotion','Otheremotion']:\n",
    "    test_df[col] = test_df[col].apply(str2list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Группируем по фразам отдельно намерения, эмоции субъекта и эмоции окружающих\n",
    "\n",
    "UPD: Убираем из строк не несущие смысла to, to be, is и точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_word(w):\n",
    "    x = w\n",
    "    if x[:3] == 'is ' or x[:3] == 'to ':\n",
    "        x = x[3:]\n",
    "    if x[:3] == 'be ':\n",
    "        x = x[3:]\n",
    "    if x[len(x) - 1] == '.':\\\n",
    "        x = x[:len(x)-1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase2oemotion = {}\n",
    "phrase2xemotion = {}\n",
    "phrase2xintent = {}\n",
    "res_xi = []\n",
    "res_xe = []\n",
    "res_oe = []\n",
    "set_xi = set()\n",
    "set_xe = set()\n",
    "set_oe = set()\n",
    "\n",
    "phrase_set = set([x for x in test_df.Event])\n",
    "\n",
    "for phrase in phrase_set:\n",
    "    for x in test_df[test_df.Event == phrase].Xintent:\n",
    "        res_xi += x\n",
    "    phrase2xintent[phrase] = set()\n",
    "    for x in set(res_xi):\n",
    "        if x != '':\n",
    "            phrase2xintent[phrase].add(clear_word(x))\n",
    "    res_xi.clear()\n",
    "    \n",
    "    for x in test_df[test_df.Event == phrase].Xemotion:\n",
    "        res_xe += x\n",
    "    phrase2xemotion[phrase] = set()\n",
    "    for x in set(res_xe):\n",
    "        if x != '':\n",
    "            phrase2xemotion[phrase].add(clear_word(x))\n",
    "    res_xe.clear()\n",
    "    \n",
    "    for x in test_df[test_df.Event == phrase].Otheremotion:\n",
    "        res_oe += x\n",
    "    phrase2oemotion[phrase] = set()\n",
    "    for x in set(res_oe):\n",
    "        if x != '':\n",
    "            phrase2oemotion[phrase].add(clear_word(x))\n",
    "    res_oe.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем recall следующим образом: из всех вариантов, выданных моделью для данной фразы, оставляем те, что есть в контрольном множестве фразы, сформированном ранее, и делим их количество на размер контрольного множества. Затем делим полученную сумму на количество фраз. Проделываем для каждого из выходов (intent, xreact и oreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_recall(predictor):\n",
    "    res_oe = 0\n",
    "    res_xe = 0\n",
    "    res_xi = 0\n",
    "\n",
    "    for phrase in phrase_set:\n",
    "        result = predictor.predict(source=phrase)\n",
    "\n",
    "        oreact = set([\" \".join(react) for react in result[\"oreact_top_k_predicted_tokens\"]])    \n",
    "        intents = set([\" \".join(react) for react in result[\"xintent_top_k_predicted_tokens\"]])\n",
    "        xreact = set([\" \".join(react) for react in result[\"xreact_top_k_predicted_tokens\"]])\n",
    "\n",
    "        res_oe += len(phrase2oemotion[phrase].intersection(oreact)) / len(phrase2oemotion[phrase])\n",
    "        res_xe += len(phrase2xemotion[phrase].intersection(xreact)) / len(phrase2xemotion[phrase])\n",
    "        res_xi += len(phrase2xintent[phrase].intersection(intents)) / len(phrase2xintent[phrase])\n",
    "\n",
    "    print(\"Recall for intents: \", res_xi / len(phrase_set))\n",
    "    print(\"Recall for x_react: \", res_xe / len(phrase_set))\n",
    "    print(\"Recall for o_react: \", res_oe / len(phrase_set))\n",
    "    print()\n",
    "    \n",
    "def count_recall_all():    \n",
    "    print(\"Model with xintent metric:\")\n",
    "    print()\n",
    "    print(\"Recall of model trained for 10 epochs\")\n",
    "    count_recall(predictor_large)\n",
    "    print(\"Recall of model trained for 5 epochs\")\n",
    "    count_recall(predictor_mid)\n",
    "    print(\"Recall of model trained for 2 epochs\")\n",
    "    count_recall(predictor_small)\n",
    "    \n",
    "    print(\"Model with xreact metric:\")\n",
    "    print()\n",
    "    print(\"Recall of model trained for 10 epochs\")\n",
    "    count_recall(predictor_xel)\n",
    "    print(\"Recall of model trained for 5 epochs\")\n",
    "    count_recall(predictor_xe)\n",
    "    \n",
    "    print(\"Model with oreact metric:\")\n",
    "    print()\n",
    "    print(\"Recall of model trained for 10 epochs\")\n",
    "    count_recall(predictor_oel)\n",
    "    print(\"Recall of model trained for 5 epochs\")\n",
    "    count_recall(predictor_oe)\n",
    "    \n",
    "    print(\"Recall of original model\")\n",
    "    count_recall(predictor_orig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with xintent metric:\n",
      "\n",
      "Recall of model trained for 10 epochs\n",
      "Recall for intents:  0.2909114863298134\n",
      "Recall for x_react:  0.1786399376040804\n",
      "Recall for o_react:  0.6410126689011149\n",
      "\n",
      "Recall of model trained for 5 epochs\n",
      "Recall for intents:  0.2824079343999664\n",
      "Recall for x_react:  0.19815658002908923\n",
      "Recall for o_react:  0.6493012078669447\n",
      "\n",
      "Recall of model trained for 2 epochs\n",
      "Recall for intents:  0.24537089736292872\n",
      "Recall for x_react:  0.2539724699087242\n",
      "Recall for o_react:  0.6486898964986615\n",
      "\n",
      "Model with xreact metric:\n",
      "\n",
      "Recall of model trained for 10 epochs\n",
      "Recall for intents:  0.2616591833723305\n",
      "Recall for x_react:  0.2460222601656857\n",
      "Recall for o_react:  0.6493855266763631\n",
      "\n",
      "Recall of model trained for 5 epochs\n",
      "Recall for intents:  0.2616591833723305\n",
      "Recall for x_react:  0.2460222601656857\n",
      "Recall for o_react:  0.6493855266763631\n",
      "\n",
      "Model with oreact metric:\n",
      "\n",
      "Recall of model trained for 10 epochs\n",
      "Recall for intents:  0.24537089736292872\n",
      "Recall for x_react:  0.2539724699087242\n",
      "Recall for o_react:  0.6486898964986615\n",
      "\n",
      "Recall of model trained for 5 epochs\n",
      "Recall for intents:  0.24537089736292872\n",
      "Recall for x_react:  0.2539724699087242\n",
      "Recall for o_react:  0.6486898964986615\n",
      "\n",
      "Recall of original model\n",
      "Recall for intents:  0.2873711503193573\n",
      "Recall for x_react:  0.383745968506925\n",
      "Recall for o_react:  0.695390923080166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_recall_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.23960876072429815\n",
      "Recall for x_react:  0.2895918969624146\n",
      "Recall for o_react:  0.6595754547945781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_recall(predictor_new_xi_2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.28993338814055963\n",
      "Recall for x_react:  0.13174813971626703\n",
      "Recall for o_react:  0.6015219545100017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_recall(predictor_new_xi_10e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.28294546681000865\n",
      "Recall for x_react:  0.2503920824637948\n",
      "Recall for o_react:  0.6500137018065305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_recall(predictor_birnn300_xi_2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.30106347098379005\n",
      "Recall for x_react:  0.20521722633276354\n",
      "Recall for o_react:  0.6448997660153045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_recall(predictor_birnn300_xi_10e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.2789202976453973\n",
      "Recall for x_react:  0.24991462720546334\n",
      "Recall for o_react:  0.6075444254727127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_recall(predictor_cnn_xi_2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for intents:  0.19982714644069197\n",
      "Recall for x_react:  0.0\n",
      "Recall for o_react:  0.5354507894348536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_recall(predictor_alyona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_friends(predictor):\n",
    "    result_file = open(\"perfect_sent_res.txt\", \"w\")\n",
    "    with open(\"perfect_sent.txt\", \"r\") as file:\n",
    "        for phrase in file:\n",
    "            result = predictor.predict(source=phrase)\n",
    "            phrase = phrase[:len(phrase)-1]\n",
    "\n",
    "            oreact = [\" \".join(react) for react in result[\"oreact_top_k_predicted_tokens\"]]    \n",
    "            intents = [\" \".join(react) for react in result[\"xintent_top_k_predicted_tokens\"]]\n",
    "            xreact = [\" \".join(react) for react in result[\"xreact_top_k_predicted_tokens\"]]\n",
    "            size = min(len(oreact), len(xreact), len(intents))\n",
    "            lines = []\n",
    "            for i in range(size):\n",
    "                lines.append(phrase + ',' + intents[i] + ',' + xreact[i] + ',' + oreact[i] + '\\n')\n",
    "\n",
    "            for line in lines:\n",
    "                result_file.write(line)\n",
    "        \n",
    "    result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_friends(predictor_alyona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_beauty(setty):\n",
    "    res_str = \"\"\n",
    "    for line in setty:\n",
    "        if line.find(\"@@UNKNOWN@@\") == -1 and line.find(\"none\") == -1:\n",
    "            res_str = res_str + line + ', '\n",
    "    return res_str[:len(int_str)-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наша команда благорадит вас за внимание \n",
      "\n",
      "Intent:  учить, быть успешным, прятаться, помогать другим, быть хорошим\n",
      "Xreact:  счастливый, хорошо, довольный, полезный, гордый, образованный,\n",
      "Oreact:  счастливый, благодарный, заинтересованный, довольный, хорошо, \n"
     ]
    }
   ],
   "source": [
    "phrase = \"Наша команда благорадит вас за внимание\"\n",
    "result = predictor_alyona.predict(source=\"Наша команда благорадит вас за внимание\")\n",
    "\n",
    "oreact = do_beauty([\" \".join(react) for react in result[\"oreact_top_k_predicted_tokens\"]])  \n",
    "intents = do_beauty([\" \".join(react) for react in result[\"xintent_top_k_predicted_tokens\"]])\n",
    "xreact = do_beauty([\" \".join(react) for react in result[\"xreact_top_k_predicted_tokens\"]])\n",
    "\n",
    "print(phrase, \"\\n\")\n",
    "print(\"Intent: \", intents)\n",
    "print(\"Xreact: \", xreact)\n",
    "print(\"Oreact: \", oreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
